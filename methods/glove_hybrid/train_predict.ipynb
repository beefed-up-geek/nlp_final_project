{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MBTI Prediction: GloVe + CNN-LSTM Hybrid (GPU Optimized)\n",
    "\n",
    "This notebook implements MBTI personality prediction using:\n",
    "- **Embedding**: GloVe (pretrained)\n",
    "- **Model**: CNN-LSTM Hybrid\n",
    "- **Task**: 4 binary classifications (E/I, N/S, T/F, P/J)\n",
    "- **Optimization**: NVIDIA RTX 3090 (24GB VRAM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. GPU Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "import pandas as pd\nimport numpy as np\nimport re, os, urllib.request, zipfile\nfrom sklearn.model_selection import train_test_split\nimport warnings\nwarnings.filterwarnings('ignore')\n\nimport tensorflow as tf\nfrom tensorflow.keras.preprocessing.text import Tokenizer\nfrom tensorflow.keras.preprocessing.sequence import pad_sequences\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.layers import *\nfrom tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras import mixed_precision\n\nimport nltk\nnltk.download('punkt', quiet=True)\nnltk.download('punkt_tab', quiet=True)\n\n# GPU Setup\ngpus = tf.config.list_physical_devices('GPU')\nif gpus:\n    for gpu in gpus:\n        tf.config.experimental.set_memory_growth(gpu, True)\n    mixed_precision.set_global_policy('mixed_float16')\n    print(f\"GPU: {len(gpus)} | Mixed Precision: ON\")\nprint(f\"TensorFlow: {tf.__version__}\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2-4. Load Data, Preprocess & Tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_URL = 'https://raw.githubusercontent.com/beefed-up-geek/nlp_final_project/refs/heads/main/kaggle_data/2025MBTItrain.csv'\n",
    "TEST_URL = 'https://raw.githubusercontent.com/beefed-up-geek/nlp_final_project/refs/heads/main/kaggle_data/2025test.csv'\n",
    "\n",
    "train_df = pd.read_csv(TRAIN_URL)\n",
    "test_df = pd.read_csv(TEST_URL)\n",
    "\n",
    "def preprocess_text(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'http\\S+|www\\S+|https\\S+', '', text, flags=re.MULTILINE)\n",
    "    text = re.sub(r'[^a-zA-Z\\s.,!?]', '', text)\n",
    "    return ' '.join(text.split())\n",
    "\n",
    "train_df['cleaned_posts'] = train_df['posts'].apply(preprocess_text)\n",
    "test_df['cleaned_posts'] = test_df['posts'].apply(preprocess_text)\n",
    "\n",
    "for i, char in enumerate(['E', 'N', 'T', 'P']):\n",
    "    col = ['E_I', 'N_S', 'T_F', 'P_J'][i]\n",
    "    train_df[col] = train_df['type'].apply(lambda x: 1 if x[i] == char else 0)\n",
    "\n",
    "MAX_WORDS = 20000\n",
    "MAX_LENGTH = 400\n",
    "\n",
    "tokenizer = Tokenizer(num_words=MAX_WORDS, oov_token='<OOV>')\n",
    "tokenizer.fit_on_texts(train_df['cleaned_posts'])\n",
    "\n",
    "X_train = pad_sequences(tokenizer.texts_to_sequences(train_df['cleaned_posts']), maxlen=MAX_LENGTH, padding='post', truncating='post')\n",
    "X_test = pad_sequences(tokenizer.texts_to_sequences(test_df['cleaned_posts']), maxlen=MAX_LENGTH, padding='post', truncating='post')\n",
    "\n",
    "print(f\"Data ready: Train {X_train.shape}, Test {X_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Load GloVe Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GLOVE_DIR = 'glove_embeddings'\n",
    "EMBEDDING_DIM = 100\n",
    "GLOVE_FILE = f'{GLOVE_DIR}/glove.6B.{EMBEDDING_DIM}d.txt'\n",
    "\n",
    "if not os.path.exists(GLOVE_FILE):\n",
    "    print(\"Downloading GloVe...\")\n",
    "    os.makedirs(GLOVE_DIR, exist_ok=True)\n",
    "    zip_path = f'{GLOVE_DIR}/glove.6B.zip'\n",
    "    urllib.request.urlretrieve('http://nlp.stanford.edu/data/glove.6B.zip', zip_path)\n",
    "    with zipfile.ZipFile(zip_path, 'r') as z:\n",
    "        z.extractall(GLOVE_DIR)\n",
    "    os.remove(zip_path)\n",
    "\n",
    "embeddings_index = {}\n",
    "with open(GLOVE_FILE, 'r', encoding='utf-8') as f:\n",
    "    for line in f:\n",
    "        values = line.split()\n",
    "        embeddings_index[values[0]] = np.asarray(values[1:], dtype='float32')\n",
    "\n",
    "vocab_size = min(len(tokenizer.word_index) + 1, MAX_WORDS)\n",
    "embedding_matrix = np.zeros((vocab_size, EMBEDDING_DIM), dtype=np.float32)\n",
    "\n",
    "for word, idx in tokenizer.word_index.items():\n",
    "    if idx >= MAX_WORDS:\n",
    "        continue\n",
    "    vec = embeddings_index.get(word)\n",
    "    embedding_matrix[idx] = vec if vec is not None else np.random.normal(0, 0.05, EMBEDDING_DIM)\n",
    "\n",
    "print(f\"Embedding matrix: {embedding_matrix.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Build CNN-LSTM Hybrid Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_hybrid_model(emb_matrix, max_len):\n",
    "    inp = Input(shape=(max_len,))\n",
    "    emb = Embedding(emb_matrix.shape[0], emb_matrix.shape[1], weights=[emb_matrix], trainable=True)(inp)\n",
    "    \n",
    "    # CNN\n",
    "    cnn = Conv1D(128, 3, activation='relu', padding='same')(emb)\n",
    "    cnn = MaxPooling1D(2)(cnn)\n",
    "    cnn = Conv1D(64, 3, activation='relu', padding='same')(cnn)\n",
    "    \n",
    "    # LSTM\n",
    "    lstm = Bidirectional(LSTM(64, dropout=0.2, recurrent_dropout=0.2))(cnn)\n",
    "    \n",
    "    # Dense\n",
    "    x = Dense(64, activation='relu')(lstm)\n",
    "    x = Dropout(0.4)(x)\n",
    "    x = Dense(32, activation='relu')(x)\n",
    "    x = Dropout(0.3)(x)\n",
    "    out = Dense(1, activation='sigmoid', dtype='float32')(x)\n",
    "    \n",
    "    model = Model(inp, out)\n",
    "    model.compile(optimizer=Adam(0.001), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Train Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64\n",
    "models = {}\n",
    "histories = {}\n",
    "\n",
    "for dim in ['E_I', 'N_S', 'T_F', 'P_J']:\n",
    "    print(f\"\\n{'='*60}\\nTraining {dim}\\n{'='*60}\")\n",
    "    \n",
    "    X_tr, X_val, y_tr, y_val = train_test_split(\n",
    "        X_train, train_df[dim].values, test_size=0.2, random_state=42, stratify=train_df[dim]\n",
    "    )\n",
    "    \n",
    "    model = create_hybrid_model(embedding_matrix, MAX_LENGTH)\n",
    "    \n",
    "    history = model.fit(\n",
    "        X_tr, y_tr, batch_size=BATCH_SIZE, epochs=50,\n",
    "        validation_data=(X_val, y_val),\n",
    "        callbacks=[\n",
    "            EarlyStopping('val_accuracy', patience=5, restore_best_weights=True, verbose=1),\n",
    "            ReduceLROnPlateau('val_loss', factor=0.5, patience=2, min_lr=1e-6, verbose=1)\n",
    "        ],\n",
    "        verbose=1\n",
    "    )\n",
    "    \n",
    "    print(f\"✓ Best: {max(history.history['val_accuracy']):.4f}\")\n",
    "    models[dim] = model\n",
    "    histories[dim] = history\n",
    "    tf.keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8-9. Predict & Save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = {dim: (models[dim].predict(X_test, batch_size=BATCH_SIZE, verbose=0) > 0.5).astype(int).flatten() \n",
    "               for dim in ['E_I', 'N_S', 'T_F', 'P_J']}\n",
    "\n",
    "submission = pd.DataFrame({'ID': test_df['ID'], **predictions})\n",
    "submission.to_csv('submission_glove_hybrid.csv', index=False)\n",
    "print(\"✓ Saved: submission_glove_hybrid.csv\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60 + \"\\nRESULTS\\n\" + \"=\"*60)\n",
    "for dim in ['E_I', 'N_S', 'T_F', 'P_J']:\n",
    "    print(f\"{dim}: {max(histories[dim].history['val_accuracy']):.4f}\")\n",
    "print(\"=\"*60)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}